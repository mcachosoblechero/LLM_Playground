{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard LLM Metrics\n",
    "\n",
    "This notebook covers the implementation of standard LLM metrics for various purposes. \n",
    "These applications and associated metrics are:\n",
    "- Translation using [IWSLT17 English-French Dataset](https://huggingface.co/datasets/IWSLT/iwslt2017) - BLUE\n",
    "- Summarization using [CNN/Daily Mail Dataset](https://huggingface.co/datasets/abisee/cnn_dailymail) - ROGUE\n",
    "- Sentiment analysis using [IMDB Movie Reviews Dataset](https://huggingface.co/datasets/stanfordnlp/imdb) - Standard classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Libraries, contanst and support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from datasets import get_dataset_config_names\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import MarianTokenizer, MarianMTModel\n",
    "from transformers import T5Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Translation tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguelcachosoblechero/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/datasets/load.py:1486: FutureWarning: The repository for iwslt2017 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/iwslt2017\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load translation dataset\n",
    "translation_full_dataset = load_dataset('iwslt2017', \"iwslt2017-en-fr\")\n",
    "\n",
    "# Divide between train, validation and test\n",
    "ds_trans_train = translation_full_dataset['train']\n",
    "ds_trans_val = translation_full_dataset['validation']\n",
    "ds_trans_test = translation_full_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text from HTML tags and extra whitespaces\n",
    "def clean_text(text: str) -> str:\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Remove from all elements of the dataset\n",
    "def clean_dataset(example):\n",
    "    \"\"\"\n",
    "    Applies the clean_text function to both the source and target texts.\n",
    "\n",
    "    Args:\n",
    "        example (dict): A single example from the dataset.\n",
    "\n",
    "    Returns:\n",
    "        dict: The example with cleaned texts.\n",
    "    \"\"\"\n",
    "    example['translation']['en'] = clean_text(example['translation']['en'])\n",
    "    example['translation']['fr'] = clean_text(example['translation']['fr'])\n",
    "    return example\n",
    "\n",
    "\n",
    "# Apply to dataset\n",
    "ds_trans_train = ds_trans_train.map(clean_dataset)\n",
    "ds_trans_val = ds_trans_val.map(clean_dataset)\n",
    "ds_trans_test = ds_trans_test.map(clean_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73862edec15d4df8970df4211d2270be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/216089 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For each sample, apply a filter that removes sentences too short or too long\n",
    "def filter_samples(sample):\n",
    "    source = sample['translation']['en']\n",
    "    target = sample['translation']['fr']\n",
    "    # Define length thresholds\n",
    "    min_length = 5\n",
    "    max_length = 128\n",
    "    # Compute lengths\n",
    "    source_len = len(source.split())\n",
    "    target_len = len(target.split())\n",
    "    # Filter condition\n",
    "    return min_length <= source_len <= max_length and min_length <= target_len <= max_length\n",
    "\n",
    "ds_trans_train = ds_trans_train.filter(filter_samples)\n",
    "ds_val_train = ds_trans_train.filter(filter_samples)\n",
    "ds_trans_train = ds_trans_train.filter(filter_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b9c96d4f8340f6a77d1fa6774c7993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'Helsinki-NLP/opus-mt-en-fr'\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a74df84eb5f4995839be31918564536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8597 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguelcachosoblechero/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    src_texts = [ex['en'] for ex in examples['translation']]\n",
    "    tgt_texts = [ex['fr'] for ex in examples['translation']]\n",
    "\n",
    "    # Tokenize inputs\n",
    "    model_inputs = tokenizer(src_texts, max_length=128, truncation=True, padding='max_length', return_tensors='pt')\n",
    "\n",
    "    # Tokenize targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(tgt_texts, max_length=128, truncation=True, padding='max_length', return_tensors='pt')\n",
    "\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "# Apply preprocessing to tokenize all input words\n",
    "tokenized_dataset = ds_trans_test.map(preprocess_function, batched=True, remove_columns=['translation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Hugging Face dataset to PyTorch tensors\n",
    "tokenized_dataset.set_format(type='torch')\n",
    "\n",
    "# Create DataLoader\n",
    "test_loader = DataLoader(tokenized_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply all samples to the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "translations = []\n",
    "references = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        # Generate translations\n",
    "        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=128)\n",
    "        \n",
    "        # Decode translations and references\n",
    "        decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)\n",
    "        \n",
    "        translations.extend(decoded_preds)\n",
    "        references.extend(decoded_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miguelcachosoblechero/opt/anaconda3/envs/NLP/lib/python3.8/site-packages/datasets/load.py:759: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/sacrebleu/sacrebleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 35.63\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric('sacrebleu')\n",
    "\n",
    "# Prepare references in the expected format\n",
    "references = [[ref] for ref in references]\n",
    "\n",
    "# Compute BLEU score\n",
    "bleu = metric.compute(predictions=translations, references=references)\n",
    "print(f\"BLEU score: {bleu['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Fine-tune the model for better translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TBD"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
